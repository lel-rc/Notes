---
title: Evidence
categories: notetheme
tags: [philosophy, critical-thinking]
comment: 1
---

# Evidence

## What is evidence?

### The Evidence Test

There is a possiblility under investigateion - a **hypothesis**, and facts are discovered that is potentially evidence for that hypothesis. 

There are two key tests we can use to determine if something is evidence for or against our hypothesis. The first is the **evidence test**:

> Is this more likely if H is true or if H is false?

For example, if we have a hypothesis like *"My friend is home when I see his bike locked up outside. His bike is locked up outside, so he is home,"* seeing the bike locked up is more likely when he is at home that when he is not, so it counts as eDeductionvidence for that hypothesis.

But if we knock on the door and he doesn't answer, it would be more likely for this to happen when he's *not* at home, so that counts as evidence *against* this hypothesis. Even if he doesn't answer the door when he *is* at home it would still count as evidence against, since it is *more likely* for him not to answer the door if he is not at home.

When an observation doesn't support either hypothesis, it is called **independent** of the hypothesis.

Remember: if the observation is more likely assuming the hypothesis is true, then it is *some* evidence for that hypothesis. That leads us to the **first rule of evidence**:

> If we get more evidence for H, we should become more confident in H.

This doesn't mean we need to *believe* H: just that we can shift our degrees of confidence *toward* belief. How much a piece of evidence shifts our confidence in a hypothesis can be determined by the **strength test**.

### The Strength Test

Think: If we have three pieces of evidence and one is twice as strong as the other pieces, if we put our weaker pieces on one side of a scale and our strong evidence on the other side it should balance out. We can quantify the strength of evidence to say *how* much stronger a piece of evidence is compared to another.

> How much more likely is this observation if H is true than if H is false?

We can estimate that it's about ten times more likely that we would make this observation about the bike being locked up when the friend is home than if the friend is away. This is called the **strength factor** (or **Bayes factor**) of the evidence.

We can restate our rules using evidence notation:

- "P" representing probability
- "E" standing for our observation, or potential evidence
- "\|" meaning *assuming* or *given*
- "~" meaning *not*

> The evidence test: is P(E\|H) greater or less than P(E\|~H)?
>
> The first rule of evidence: If P(E\|H)>P(E\|~H), learning E should make us more confident in H
>
> The strength test: How many times greater is P(E\|H) than P(E\|~H)?

We need a comparative answer for the strength test. We divide P(E\|H) by P(E\|~H) to get our strength factor. If we get a strength factor less than 1, that observation was *less likely* given H, so it is evidence against H. Strong evidence usually has a strength factor of or greater than 10.

**Maximally strong** evidence for H means that it is impossible for that observation to exist if H was not true. That would require P(E\|H) to be greater than zero and P(E\|~H) to *be* zero. [Dividing these numbers would not make sense: it would be dividing by zero, so technically the strength test doesn't make sense here.] The strength test also gives us a way to measure the *suppositional strength* of an argument when we treat its premises as evidence. An argument with known premises that entails its conclusion is maximally suppositionally strong.

### Evidence and Probability

How likely a piece of evidence is is simply determined by our **degree of confidence** in that claim. It works much like a scale:

- I suspect it's raining
- It's probably raining
- I'm pretty sure it's raining
- I'm fairly confident it's raining

We can pretend that they are precise and give them a value between 1 and 0, where 1 is certainty the claim is true and 0 is certainty that the claim is false. If we are equally confident that it's not raining as we are that it is, we are 0.5 or 50% confident that it is raining. Our use of language expresses our degrees of confidence, i.e. *probably* vs. *pretty sure*. Remember that probability in this course means *confidence*, not *literal* probability as determined in, say, a statistics class.

We can't simply assign any degree of confidence to things; for example, we should be 1/52 sure that an ace of spades will be selected from a deck of cards and that it's 50% likely that we get heads from a coin toss.

Remember our degrees of confidence should add up to one. It doesn't make sense to be 80% sure it's raining but 60% sure that it is not - if we assign a probability of *n* to H, we should assign a probability of 1-*n* to H.

## Selection effects

**Selection effects** make observations available to us in a way that makes our evidence unreliable if we are unaware.

### Survival and Attrition

In the most dramatic type of selection effect, sources of information are eliminated entirely and we can only observe those that survive. This is known as **survivor bias**. 

Survivor biases are common in real life - even scientists aren't immune to it. When conducting a study, some people may drop out, creating an **attrition bias**. These both weaken the evidence provided for the hypothesis.

### Selective recall

We often only remember memories that involve intense emotions or that aren't hidden by other memories in the same series of events. This can happen due to *how the question is framed*.

If we ask "Are most Italians friendly?" we will tend to search our memory for friendly Italians; but if we ask "Are most Italians unfriendly?" we will tend to search our memory for *unfriendly* Italians. If we know enough of both kinds, both questions are framed in a way that we could say "yes" to either.

The **serial position effect** makes it so that we often only remember the *first* and *last* parts of an event. We may only think of the Italians we met at the beginning of the trip and the ones we met by the end.

### Selective noticing

It's hard to stop noticing things when it gets into our brain. Coincidences can become magnified; take the example of medical emergencies happening during the full moon.

|                 | more events   | fewer events  |
| --------------- | ------------- | ------------- |
| moon is full    | confirming    | disconfirming |
| moon isn't full | disconfirming | confirming    |

We don't notice when the moon isn't full, so we don't associate it with medical emergencies. But when it is, out brains immediately take note and start to associate the two. 

## Media biases

**Media bias** is the term often used to talk about political bias in popular media, but there is a much more pervasive bias throughout all of media - they are biased towards content that is *engaging*, that holds our attention.

### News and fear

24-hour news programs usually only focus on things that have an impact on viewer's lives. That is why we often see more *scary news stories* than not. Deer are responsible for more injuries and deaths than sharks; however, sharks feel scarier than deer. This is what the media coverage responds to.

If we actually look at the statistics for what people die of, it's rarely terrorists, school shootings, or sharks. But these are the stories that engage the viewer, and so are often more reported on. This can take advantage of our System 1 processes and make it seem more likely to die of these causes than it really is.

### Echo chambers

News outlets are especially concerned with content that is engaging to their *primary audience*. For a news outlet with a political inclination, this means reporting material that plays to the expectations of people on one part of the political spectrum

Even if all these reports are accurate, they do end to skew our impression of how common the reported events are. Social media makes this problem worse, as they often tailor content to your specific beliefs and worldviews. Given our natural inclination towards confirmation bias, no wonder political polarization is on the rise!

### Research media

Studies in scientific journals that merely support conventional wisdom is often passed over because they are boring. This is called the **publication bias**.

Researchers, aware of this bias, often choose not to publish a study in a particular journal or even not to pursue an area of research at all. This is called the **file drawer effect** - your data goes in the file drawer and is never seen by the scientific community at large.

How many studies with evidence against a surprising claim are hidden away in file drawers? This may make it seem like the less-interesting, unsurprising claim is *less likely than the surprising one*, even if it actually is more likely. 





